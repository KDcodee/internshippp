{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Trash Bin Level Prediction System\n",
    "\n",
    "## Project Overview\n",
    "This project aims to develop machine learning models to predict when garbage bins will need to be emptied, optimizing waste collection operations and improving urban sanitation management.\n",
    "\n",
    "## Dataset Features\n",
    "- **BIN ID**: Unique identifier for each bin\n",
    "- **Date & Time**: Temporal information\n",
    "- **Fill Level**: Current fill level in liters\n",
    "- **Fill Percentage**: Percentage of bin capacity filled\n",
    "- **Location**: Geographic location\n",
    "- **Temperature**: Environmental temperature\n",
    "- **Battery Level**: Sensor battery status\n",
    "- **Target**: Fill Level Indicator (Above 550L) - Binary classification\n",
    "\n",
    "## Objectives\n",
    "1. Develop binary classification models to predict bin fill status\n",
    "2. Evaluate model performance using multiple metrics\n",
    "3. Implement route optimization for collection vehicles\n",
    "4. Generate actionable insights for waste management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Route optimization\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel('trash_data.xlsx')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "\n",
    "# Display basic information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing values\n",
    "if not missing_df.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(missing_df.index, missing_df['Missing Count'])\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Missing Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('‚Å∞', '')\n",
    "print(\"Cleaned column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=['FILL_LEVEL_INDICATORABOVE_550'])  # Remove rows with missing target\n",
    "df['FILL_LEVELIN_LITRES'].fillna(df['FILL_LEVELIN_LITRES'].median(), inplace=True)\n",
    "df['FILL_PERCENTAGE'].fillna(df['FILL_PERCENTAGE'].median(), inplace=True)\n",
    "\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types and extract features\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['TIME'] = pd.to_datetime(df['TIME'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Extract temporal features\n",
    "df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['hour'] = pd.to_datetime(df['TIME'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Convert coordinates to numeric\n",
    "df['LATITUDE'] = pd.to_numeric(df['LATITUDE'], errors='coerce')\n",
    "df['LONGITUDE'] = pd.to_numeric(df['LONGITUDE'], errors='coerce')\n",
    "df['TEMPERATURE_IN_C'] = pd.to_numeric(df['TEMPERATURE_IN_C'], errors='coerce')\n",
    "\n",
    "# Encode categorical variables\n",
    "le_bin = LabelEncoder()\n",
    "le_location = LabelEncoder()\n",
    "\n",
    "df['BIN_ID_encoded'] = le_bin.fit_transform(df['BIN_ID'])\n",
    "df['LOCATION_encoded'] = le_location.fit_transform(df['LOCATION_'])\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New features added: day_of_week, month, day, hour, BIN_ID_encoded, LOCATION_encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "target_counts = df['FILL_LEVEL_INDICATORABOVE_550'].value_counts()\n",
    "target_percentage = df['FILL_LEVEL_INDICATORABOVE_550'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(f\"Not Full (0): {target_counts[0]} ({target_percentage[0]:.1f}%)\")\n",
    "print(f\"Full (1): {target_counts[1]} ({target_percentage[1]:.1f}%)\")\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot\n",
    "target_counts.plot(kind='bar', ax=ax1, color=['skyblue', 'orange'])\n",
    "ax1.set_title('Bin Fill Level Distribution')\n",
    "ax1.set_xlabel('Fill Status (0: Not Full, 1: Full)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(target_counts.values, labels=['Not Full', 'Full'], autopct='%1.1f%%', colors=['skyblue', 'orange'])\n",
    "ax2.set_title('Bin Fill Level Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill level distribution by location\n",
    "plt.figure(figsize=(12, 6))\n",
    "location_fill = df.groupby('LOCATION_')['FILL_LEVEL_INDICATORABOVE_550'].mean().sort_values(ascending=False)\n",
    "location_fill.plot(kind='bar')\n",
    "plt.title('Average Fill Rate by Location')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Average Fill Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 locations with highest fill rates:\")\n",
    "print(location_fill.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Fill rate by day of week\n",
    "day_fill = df.groupby('day_of_week')['FILL_LEVEL_INDICATORABOVE_550'].mean()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0,0].bar(range(7), day_fill.values)\n",
    "axes[0,0].set_title('Fill Rate by Day of Week')\n",
    "axes[0,0].set_xlabel('Day of Week')\n",
    "axes[0,0].set_ylabel('Average Fill Rate')\n",
    "axes[0,0].set_xticks(range(7))\n",
    "axes[0,0].set_xticklabels(day_names)\n",
    "\n",
    "# Fill rate by hour\n",
    "hour_fill = df.groupby('hour')['FILL_LEVEL_INDICATORABOVE_550'].mean()\n",
    "axes[0,1].plot(hour_fill.index, hour_fill.values, marker='o')\n",
    "axes[0,1].set_title('Fill Rate by Hour of Day')\n",
    "axes[0,1].set_xlabel('Hour')\n",
    "axes[0,1].set_ylabel('Average Fill Rate')\n",
    "\n",
    "# Fill rate by month\n",
    "month_fill = df.groupby('month')['FILL_LEVEL_INDICATORABOVE_550'].mean()\n",
    "axes[1,0].bar(month_fill.index, month_fill.values)\n",
    "axes[1,0].set_title('Fill Rate by Month')\n",
    "axes[1,0].set_xlabel('Month')\n",
    "axes[1,0].set_ylabel('Average Fill Rate')\n",
    "\n",
    "# Temperature vs Fill Rate\n",
    "temp_bins = pd.cut(df['TEMPERATURE_IN_C'], bins=10)\n",
    "temp_fill = df.groupby(temp_bins)['FILL_LEVEL_INDICATORABOVE_550'].mean()\n",
    "axes[1,1].plot(range(len(temp_fill)), temp_fill.values, marker='o')\n",
    "axes[1,1].set_title('Fill Rate by Temperature')\n",
    "axes[1,1].set_xlabel('Temperature Bins')\n",
    "axes[1,1].set_ylabel('Average Fill Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_columns = ['FILL_LEVELIN_LITRES', 'TOTALLITRES', 'FILL_PERCENTAGE', \n",
    "                   'LATITUDE', 'LONGITUDE', 'TEMPERATURE_IN_C', 'BATTERY_LEVEL_',\n",
    "                   'day_of_week', 'month', 'hour', 'FILL_LEVEL_INDICATORABOVE_550']\n",
    "\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlations with target variable\n",
    "target_correlations = correlation_matrix['FILL_LEVEL_INDICATORABOVE_550'].abs().sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with Target Variable (absolute values):\")\n",
    "print(target_correlations[1:])  # Exclude self-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "feature_columns = ['FILL_LEVELIN_LITRES', 'TOTALLITRES', 'FILL_PERCENTAGE',\n",
    "                   'TEMPERATURE_IN_C', 'BATTERY_LEVEL_', 'day_of_week', 'month', 'hour',\n",
    "                   'BIN_ID_encoded', 'LOCATION_encoded']\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df['FILL_LEVEL_INDICATORABOVE_550'].copy()\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"\\nFeatures used: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(f\"Scaled training set shape: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"Models initialized:\")\n",
    "for name in models.keys():\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "predictions = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for models that benefit from it\n",
    "    if name in ['Logistic Regression', 'SVM', 'KNN', 'Naive Bayes']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc\n",
    "    }\n",
    "    \n",
    "    predictions[name] = {\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results comparison table\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//3, i%3]\n",
    "    results_df[metric].plot(kind='bar', ax=ax, color='skyblue')\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[1, 2].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify best model\n",
    "best_model_name = results_df.index[0]\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"F1-Score: {results_df.loc[best_model_name, 'F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, pred_data) in enumerate(predictions.items()):\n",
    "    if i < 7:  # We have 7 models\n",
    "        cm = confusion_matrix(y_test, pred_data['predictions'])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "        axes[i].set_title(f'{name} - Confusion Matrix')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(7, 9):\n",
    "    axes[j].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, pred_data in predictions.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, pred_data['probabilities'])\n",
    "    auc_score = roc_auc_score(y_test, pred_data['probabilities'])\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for tree-based models\n",
    "tree_models = ['Random Forest', 'Decision Tree', 'Gradient Boosting']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, model_name in enumerate(tree_models):\n",
    "    if model_name in trained_models:\n",
    "        model = trained_models[model_name]\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_columns,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        axes[i].barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "        axes[i].set_yticks(range(len(feature_importance)))\n",
    "        axes[i].set_yticklabels(feature_importance['feature'])\n",
    "        axes[i].set_title(f'{model_name} - Feature Importance')\n",
    "        axes[i].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance for best model\n",
    "if best_model_name in tree_models:\n",
    "    best_model = trained_models[best_model_name]\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature Importance - {best_model_name}:\")\n",
    "    print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Route Optimization for Collection Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bins that need collection (predicted as full)\n",
    "best_predictions = predictions[best_model_name]['predictions']\n",
    "test_indices = X_test.index\n",
    "\n",
    "# Create a dataframe with test predictions\n",
    "test_results = df.loc[test_indices].copy()\n",
    "test_results['predicted_full'] = best_predictions\n",
    "\n",
    "# Filter bins that need collection\n",
    "bins_to_collect = test_results[test_results['predicted_full'] == 1].copy()\n",
    "\n",
    "print(f\"Total bins in test set: {len(test_results)}\")\n",
    "print(f\"Bins predicted to need collection: {len(bins_to_collect)}\")\n",
    "print(f\"Collection rate: {len(bins_to_collect)/len(test_results)*100:.1f}%\")\n",
    "\n",
    "# Show sample of bins to collect\n",
    "if len(bins_to_collect) > 0:\n",
    "    print(\"\\nSample bins requiring collection:\")\n",
    "    sample_cols = ['BIN_ID', 'LOCATION_', 'FILL_PERCENTAGE', 'LATITUDE', 'LONGITUDE']\n",
    "    print(bins_to_collect[sample_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route optimization using nearest neighbor heuristic\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate Euclidean distance between two points (simplified for demo)\"\"\"\n",
    "    return np.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2)\n",
    "\n",
    "def optimize_route(bins_df, start_location=None):\n",
    "    \"\"\"Simple nearest neighbor route optimization\"\"\"\n",
    "    if len(bins_df) == 0:\n",
    "        return [], 0\n",
    "    \n",
    "    bins = bins_df.copy()\n",
    "    route = []\n",
    "    total_distance = 0\n",
    "    \n",
    "    # Start from first bin if no start location specified\n",
    "    if start_location is None:\n",
    "        current_idx = bins.index[0]\n",
    "    else:\n",
    "        # Find nearest bin to start location\n",
    "        distances = bins.apply(\n",
    "            lambda x: calculate_distance(start_location[0], start_location[1], \n",
    "                                       x['LATITUDE'], x['LONGITUDE']), axis=1\n",
    "        )\n",
    "        current_idx = distances.idxmin()\n",
    "    \n",
    "    unvisited = set(bins.index)\n",
    "    \n",
    "    while unvisited:\n",
    "        route.append(current_idx)\n",
    "        unvisited.remove(current_idx)\n",
    "        \n",
    "        if not unvisited:\n",
    "            break\n",
    "        \n",
    "        # Find nearest unvisited bin\n",
    "        current_lat, current_lon = bins.loc[current_idx, ['LATITUDE', 'LONGITUDE']]\n",
    "        distances = {}\n",
    "        \n",
    "        for idx in unvisited:\n",
    "            next_lat, next_lon = bins.loc[idx, ['LATITUDE', 'LONGITUDE']]\n",
    "            distances[idx] = calculate_distance(current_lat, current_lon, next_lat, next_lon)\n",
    "        \n",
    "        next_idx = min(distances, key=distances.get)\n",
    "        total_distance += distances[next_idx]\n",
    "        current_idx = next_idx\n",
    "    \n",
    "    return route, total_distance\n",
    "\n",
    "# Optimize route for bins that need collection\n",
    "if len(bins_to_collect) > 0:\n",
    "    # Filter bins with valid coordinates\n",
    "    valid_bins = bins_to_collect.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
    "    \n",
    "    if len(valid_bins) > 0:\n",
    "        print(f\"\\nOptimizing route for {len(valid_bins)} bins with valid coordinates...\")\n",
    "        \n",
    "        # Get optimized route\n",
    "        route_indices, total_distance = optimize_route(valid_bins)\n",
    "        \n",
    "        print(f\"Total route distance: {total_distance:.4f} units\")\n",
    "        print(f\"Average distance per bin: {total_distance/len(route_indices):.4f} units\")\n",
    "        \n",
    "        # Create route dataframe\n",
    "        route_df = valid_bins.loc[route_indices].copy()\n",
    "        route_df['route_order'] = range(1, len(route_df) + 1)\n",
    "        \n",
    "        print(\"\\nOptimized collection route (first 10 stops):\")\n",
    "        route_cols = ['route_order', 'BIN_ID', 'LOCATION_', 'FILL_PERCENTAGE', 'LATITUDE', 'LONGITUDE']\n",
    "        print(route_df[route_cols].head(10))\n",
    "    else:\n",
    "        print(\"No bins with valid coordinates for route optimization\")\n",
    "else:\n",
    "    print(\"No bins predicted to need collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bins and route on map\n",
    "if len(bins_to_collect) > 0 and len(valid_bins) > 0:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add all bins (not full)\n",
    "    normal_bins = test_results[test_results['predicted_full'] == 0]\n",
    "    normal_bins_valid = normal_bins.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
    "    \n",
    "    if len(normal_bins_valid) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=normal_bins_valid['LONGITUDE'],\n",
    "            y=normal_bins_valid['LATITUDE'],\n",
    "            mode='markers',\n",
    "            marker=dict(color='green', size=6),\n",
    "            name='Normal Bins',\n",
    "            text=normal_bins_valid['BIN_ID'],\n",
    "            hovertemplate='Bin: %{text}<br>Fill: %{customdata:.1f}%<extra></extra>',\n",
    "            customdata=normal_bins_valid['FILL_PERCENTAGE']\n",
    "        ))\n",
    "    \n",
    "    # Add full bins\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=valid_bins['LONGITUDE'],\n",
    "        y=valid_bins['LATITUDE'],\n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=10),\n",
    "        name='Bins to Collect',\n",
    "        text=valid_bins['BIN_ID'],\n",
    "        hovertemplate='Bin: %{text}<br>Fill: %{customdata:.1f}%<extra></extra>',\n",
    "        customdata=valid_bins['FILL_PERCENTAGE']\n",
    "    ))\n",
    "    \n",
    "    # Add route lines\n",
    "    if len(route_indices) > 1:\n",
    "        route_lats = [valid_bins.loc[idx, 'LATITUDE'] for idx in route_indices]\n",
    "        route_lons = [valid_bins.loc[idx, 'LONGITUDE'] for idx in route_indices]\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=route_lons,\n",
    "            y=route_lats,\n",
    "            mode='lines',\n",
    "            line=dict(color='blue', width=2),\n",
    "            name='Optimized Route',\n",
    "            hoverinfo='skip'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Trash Bin Collection Route Optimization',\n",
    "        xaxis_title='Longitude',\n",
    "        yaxis_title='Latitude',\n",
    "        hovermode='closest',\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data available for route visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Deployment and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and preprocessing objects\n",
    "import joblib\n",
    "\n",
    "model_artifacts = {\n",
    "    'model': trained_models[best_model_name],\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': feature_columns,\n",
    "    'label_encoders': {\n",
    "        'bin_id': le_bin,\n",
    "        'location': le_location\n",
    "    },\n",
    "    'model_name': best_model_name,\n",
    "    'performance_metrics': results[best_model_name]\n",
    "}\n",
    "\n",
    "# Save model artifacts\n",
    "joblib.dump(model_artifacts, 'trash_bin_model.pkl')\n",
    "print(f\"Model artifacts saved successfully!\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Model performance: {results[best_model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction function\n",
    "def predict_bin_status(bin_data, model_artifacts):\n",
    "    \"\"\"\n",
    "    Predict if a trash bin needs collection\n",
    "    \n",
    "    Args:\n",
    "        bin_data: Dictionary with bin information\n",
    "        model_artifacts: Loaded model artifacts\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction and probability\n",
    "    \"\"\"\n",
    "    model = model_artifacts['model']\n",
    "    scaler = model_artifacts['scaler']\n",
    "    feature_columns = model_artifacts['feature_columns']\n",
    "    \n",
    "    # Create feature vector\n",
    "    features = []\n",
    "    for col in feature_columns:\n",
    "        if col in bin_data:\n",
    "            features.append(bin_data[col])\n",
    "        else:\n",
    "            features.append(0)  # Default value for missing features\n",
    "    \n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    \n",
    "    # Scale features if needed\n",
    "    model_name = model_artifacts['model_name']\n",
    "    if model_name in ['Logistic Regression', 'SVM', 'KNN', 'Naive Bayes']:\n",
    "        features_scaled = scaler.transform(features_array)\n",
    "        prediction = model.predict(features_scaled)[0]\n",
    "        probability = model.predict_proba(features_scaled)[0][1]\n",
    "    else:\n",
    "        prediction = model.predict(features_array)[0]\n",
    "        probability = model.predict_proba(features_array)[0][1]\n",
    "    \n",
    "    return {\n",
    "        'needs_collection': bool(prediction),\n",
    "        'probability': float(probability),\n",
    "        'model_used': model_name\n",
    "    }\n",
    "\n",
    "# Test the prediction function\n",
    "sample_bin = {\n",
    "    'FILL_LEVELIN_LITRES': 600,\n",
    "    'TOTALLITRES': 1000,\n",
    "    'FILL_PERCENTAGE': 60,\n",
    "    'TEMPERATURE_IN_C': 25,\n",
    "    'BATTERY_LEVEL_': 0.8,\n",
    "    'day_of_week': 1,\n",
    "    'month': 11,\n",
    "    'hour': 14,\n",
    "    'BIN_ID_encoded': 1,\n",
    "    'LOCATION_encoded': 0\n",
    "}\n",
    "\n",
    "prediction_result = predict_bin_status(sample_bin, model_artifacts)\n",
    "print(\"\\nSample prediction:\")\n",
    "print(f\"Bin data: {sample_bin}\")\n",
    "print(f\"Prediction: {prediction_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Business Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate business insights\n",
    "print(\"=\" * 60)\n",
    "print(\"BUSINESS INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Model performance insights\n",
    "print(f\"\\n1. MODEL PERFORMANCE\")\n",
    "print(f\"   - Best performing model: {best_model_name}\")\n",
    "print(f\"   - Accuracy: {results[best_model_name]['Accuracy']:.1%}\")\n",
    "print(f\"   - Precision: {results[best_model_name]['Precision']:.1%}\")\n",
    "print(f\"   - Recall: {results[best_model_name]['Recall']:.1%}\")\n",
    "print(f\"   - F1-Score: {results[best_model_name]['F1-Score']:.1%}\")\n",
    "\n",
    "# Data insights\n",
    "print(f\"\\n2. DATA INSIGHTS\")\n",
    "print(f\"   - Dataset size: {len(df):,} records\")\n",
    "print(f\"   - Bin fill rate: {df['FILL_LEVEL_INDICATORABOVE_550'].mean():.1%}\")\n",
    "print(f\"   - Number of unique bins: {df['BIN_ID'].nunique()}\")\n",
    "print(f\"   - Number of locations: {df['LOCATION_'].nunique()}\")\n",
    "print(f\"   - Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Top locations by fill rate\n",
    "top_locations = df.groupby('LOCATION_')['FILL_LEVEL_INDICATORABOVE_550'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "print(f\"\\n3. HIGH-PRIORITY LOCATIONS (Top 5)\")\n",
    "for i, (location, stats) in enumerate(top_locations.head().iterrows()):\n",
    "    print(f\"   {i+1}. {location}: {stats['mean']:.1%} fill rate ({stats['count']} records)\")\n",
    "\n",
    "# Temporal patterns\n",
    "day_fill = df.groupby('day_of_week')['FILL_LEVEL_INDICATORABOVE_550'].mean()\n",
    "peak_day = day_fill.idxmax()\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "hour_fill = df.groupby('hour')['FILL_LEVEL_INDICATORABOVE_550'].mean()\n",
    "peak_hour = hour_fill.idxmax()\n",
    "\n",
    "print(f\"\\n4. TEMPORAL PATTERNS\")\n",
    "print(f\"   - Peak fill day: {day_names[peak_day]} ({day_fill[peak_day]:.1%} fill rate)\")\n",
    "print(f\"   - Peak fill hour: {peak_hour}:00 ({hour_fill[peak_hour]:.1%} fill rate)\")\n",
    "\n",
    "# Environmental factors\n",
    "temp_corr = df[['TEMPERATURE_IN_C', 'FILL_LEVEL_INDICATORABOVE_550']].corr().iloc[0,1]\n",
    "battery_corr = df[['BATTERY_LEVEL_', 'FILL_LEVEL_INDICATORABOVE_550']].corr().iloc[0,1]\n",
    "\n",
    "print(f\"\\n5. ENVIRONMENTAL FACTORS\")\n",
    "print(f\"   - Temperature correlation with fill level: {temp_corr:.3f}\")\n",
    "print(f\"   - Battery level correlation with fill level: {battery_corr:.3f}\")\n",
    "\n",
    "# Collection efficiency\n",
    "if 'route_df' in locals() and len(route_df) > 0:\n",
    "    avg_fill = route_df['FILL_PERCENTAGE'].mean()\n",
    "    print(f\"\\n6. COLLECTION EFFICIENCY\")\n",
    "    print(f\"   - Bins requiring collection: {len(bins_to_collect)}\")\n",
    "    print(f\"   - Average fill percentage of flagged bins: {avg_fill:.1f}%\")\n",
    "    print(f\"   - Estimated route distance: {total_distance:.4f} units\")\n",
    "\n",
    "print(f\"\\n7. RECOMMENDATIONS\")\n",
    "print(f\"   - Deploy {best_model_name} model for real-time predictions\")\n",
    "print(f\"   - Focus collection efforts on high-priority locations\")\n",
    "print(f\"   - Schedule collections during peak hours: {peak_hour}:00\")\n",
    "print(f\"   - Implement route optimization to reduce travel distance\")\n",
    "print(f\"   - Monitor sensor battery levels for maintenance\")\n",
    "print(f\"   - Consider temperature effects on waste generation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Summary and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive model summary\n",
    "model_summary = {\n",
    "    'project_info': {\n",
    "        'title': 'AI-Powered Trash Bin Level Prediction System',\n",
    "        'dataset_size': len(df),\n",
    "        'features_used': len(feature_columns),\n",
    "        'date_range': f\"{df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\"\n",
    "    },\n",
    "    'best_model': {\n",
    "        'name': best_model_name,\n",
    "        'performance': results[best_model_name],\n",
    "        'features': feature_columns\n",
    "    },\n",
    "    'all_models_performance': results,\n",
    "    'data_insights': {\n",
    "        'bin_fill_rate': float(df['FILL_LEVEL_INDICATORABOVE_550'].mean()),\n",
    "        'unique_bins': int(df['BIN_ID'].nunique()),\n",
    "        'unique_locations': int(df['LOCATION_'].nunique()),\n",
    "        'peak_day': int(peak_day),\n",
    "        'peak_hour': int(peak_hour)\n",
    "    },\n",
    "    'route_optimization': {\n",
    "        'bins_to_collect': len(bins_to_collect) if 'bins_to_collect' in locals() else 0,\n",
    "        'total_distance': float(total_distance) if 'total_distance' in locals() else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary to JSON\n",
    "import json\n",
    "with open('model_summary.json', 'w') as f:\n",
    "    json.dump(model_summary, f, indent=2)\n",
    "\n",
    "print(\"Model summary saved to 'model_summary.json'\")\n",
    "print(\"\\nProject completed successfully!\")\n",
    "print(\"\\nDeliverables created:\")\n",
    "print(\"1. trash_bin_ml_analysis.ipynb - This Jupyter notebook with complete analysis\")\n",
    "print(\"2. trash_data.xlsx - Dataset used for the project\")\n",
    "print(\"3. trash_bin_model.pkl - Trained model artifacts\")\n",
    "print(\"4. model_summary.json - Comprehensive model summary\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"- Create README.md file with project aims and results\")\n",
    "print(\"- Generate detailed PDF report\")\n",
    "print(\"- Deploy model for real-time predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}